{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISP-2022. NNSC. Homework1(Chernyy Vladimir).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flopco-pytorch"
      ],
      "metadata": {
        "id": "1VlieDN_kQcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb048674-5847-4fc8-f58d-ed2aa8ef4c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flopco-pytorch\n",
            "  Downloading flopco_pytorch-0.1.4-py3-none-any.whl (4.6 kB)\n",
            "Installing collected packages: flopco-pytorch\n",
            "Successfully installed flopco-pytorch-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9oLqQbQc8JO"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import torch\n",
        "from torch import nn\n",
        "import flopco\n",
        "from flopco import FlopCo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = input('Enter your full name and press Enter:')\n",
        "randseed_str = hashlib.sha256(name.encode('utf-8')).hexdigest()\n",
        "randseed = int(randseed_str[:10], 16)\n",
        "print(randseed)"
      ],
      "metadata": {
        "id": "lhFW44KkdBg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d0569a-de2a-415c-dfd6-dd0724958fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your full name and press Enter:Chernyy Vladimir\n",
            "505329706951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1 [1 point]\n",
        "\n",
        "Convert bytes to KB and MB "
      ],
      "metadata": {
        "id": "Y4twIHOHh-hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_bytes = randseed\n",
        "n_KB = n_bytes / 2**10\n",
        "n_MB = n_KB / 2**10"
      ],
      "metadata": {
        "id": "aQfhG9GffwGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_KB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9CFJjaZXs0Z",
        "outputId": "e99eb4e0-b003-41e3-9c94-83264b43cbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "493486041.94433594"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_MB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3biuGx8ZXuPg",
        "outputId": "3cd6ee42-b87d-4d57-cad9-8f51319082aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "481919.96283626556"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 [1 point]\n",
        "\n",
        "Let $X$ and $Y$ be an input and output vectors to fully-connected layer of the following type:\n",
        " $$Y = layer(X) = W^T@X,$$\n",
        " where $W$ is a weight matrix of size $N_{in} \\times N_{out}$\n",
        " (in this task,  bias = None)\n",
        "\n",
        " Compute\n",
        " - FLOP\n",
        " - MAC"
      ],
      "metadata": {
        "id": "oHAlmjQflQ_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's replace $N_{in}$ and $N_{out}$ with just $n$ and $m$ correspondigly to increase readability.  \n",
        "\n",
        "Given: $$W = \\begin{pmatrix}\n",
        "w^0_0 & w^1_0 & \\cdots & w^{m -1}_0 \\\\\n",
        "w^0_1 & w^1_1 & \\cdots & w^{m -1}_1 \\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
        "w^0_{n-1} & w^1_{n-1} & \\cdots & w^{m-1}_{n-1}\n",
        "\\end{pmatrix}\n",
        ", X = \\begin{pmatrix}\n",
        "x_0 \\\\\n",
        "x_1 \\\\\n",
        "\\vdots \\\\\n",
        "x_{n-1}\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Where lower indices in $W$ correspond to feature's id, upper represent neuron's id."
      ],
      "metadata": {
        "id": "26-IenoulQKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, $$Y = \\left\\{ w^j \\cdot X\\right\\}_{j=0}^{m-1}$$"
      ],
      "metadata": {
        "id": "jQCM2dfYb3zn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could fairly say, that computation of $y_i$ takes $n$ multiplications and $(n - 1)$ summations.\n",
        "\n",
        "Thus, overall number of computations for $Y$ like following:\n",
        "\n",
        "**multiplications:** $m \\cdot n\\quad$ *OR* $\\quad$ $N_{out} \\cdot N_{in}$\n",
        "\n",
        "**summations:** $m \\cdot (n - 1)\\quad$ *OR* $\\quad$ $N_{out} \\cdot (N_{in} - 1)$"
      ],
      "metadata": {
        "id": "M1_LVgMzil0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's translate in for conventional units:\n",
        "\n",
        "**FLOPS** $= N_{out} \\cdot N_{in} + N_{out} \\cdot (N_{in} - 1) = N_{out} \\cdot (2N_{in} - 1)$\n",
        "\n",
        "**MAC** $= N_{out} \\cdot N_{in}\\quad$ same logic, but after we found scalar product we consider every pair of $(+, *)$ as \"1\" when accumulating$"
      ],
      "metadata": {
        "id": "C5ssMUSxtb7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3 [3 points]\n",
        "Consider a convolutional layer, such that\n",
        "\n",
        "- $H_{in} = W_{in} = 11$\n",
        "- $k_{in} = k_{out} = 3$\n",
        "- $C_{in} = C_{out} = 16$\n",
        "\n",
        "Assume $H_{out} = W_{out} = 9$\n",
        "\n",
        "a) [1 point] $padding_{h} = padding_{w}$ - ?\n",
        "\n",
        "b) [1 point] FLOP and MAC for standard convolution - ? \n",
        "\n",
        "c) [1 point] FLOP and MAC for depth-wise convolution -?"
      ],
      "metadata": {
        "id": "rDrcwOJFmrvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a)**"
      ],
      "metadata": {
        "id": "lR3Yfd0dHpO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using formula from [article](https://medium.com/analytics-vidhya/convolution-padding-stride-and-pooling-in-cnn-13dc1f3ada26) for our case:"
      ],
      "metadata": {
        "id": "hNgfW9xgHq4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$H_{out} = H_{in} + 2 \\cdot \\text{padding}_{h} - k_{in}+1$\n",
        "\n",
        "$W_{out} = W_{in} + 2 \\cdot \\text{padding}_{w} - k_{in}+1$"
      ],
      "metadata": {
        "id": "Vp0FAtgdHz7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Substituting known variables:"
      ],
      "metadata": {
        "id": "H6Cq7PM0Lee9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{cases} \n",
        "11 + 2 \\cdot \\text{padding}_{h} - 3 + 1 = 9\\\\\n",
        "11 + 2 \\cdot \\text{padding}_{w} - 3 + 1 = 9\n",
        "\\end{cases}"
      ],
      "metadata": {
        "id": "k5-E9lbHJH37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expressing unknown:"
      ],
      "metadata": {
        "id": "ZygD6EdOLeLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{cases} \n",
        "2 \\cdot \\text{padding}_{h} = 0\\\\\n",
        "2 \\cdot \\text{padding}_{w} = 0\n",
        "\\end{cases}"
      ],
      "metadata": {
        "id": "CqYjaDqALcIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's only possible in case, when padding_{h} = padding_{w} = 0"
      ],
      "metadata": {
        "id": "ZSI3zCusLy-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: **yes**"
      ],
      "metadata": {
        "id": "Dgr_kjMuL8sF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c)**"
      ],
      "metadata": {
        "id": "S7rQPed0Q85X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of matrix product positions $=W_{out} \\cdot H_{out}$\n",
        "\n",
        "Every iteration of computing convolution matrix is just elementwise products and following summation:\n",
        "\n",
        "Number of matrix product positions $=W_{out} \\cdot H_{out}$\n",
        "\n",
        "Every iteration of computing convolution matrix is just elementwise products and following summation."
      ],
      "metadata": {
        "id": "bTbCNmWONJi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**multiplications:** $C_{out} \\cdot W_{out} \\cdot H_{out}  \\cdot k_{in} \\cdot k_{out}$\n",
        "\n",
        "**summations:** $C_{out} \\cdot W_{out} \\cdot H_{out}  \\cdot (k_{in} \\cdot k_{out} - 1)$ "
      ],
      "metadata": {
        "id": "17yE5AY3OOqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Let's translate in for conventional units:\n",
        "\n",
        "**FLOPS** $= C_{out} \\cdot W_{out} \\cdot H_{out}  \\cdot(2 k_{in} \\cdot k_{out} - 1)$\n",
        "\n",
        "**MAC** $= C_{out} \\cdot W_{out} \\cdot H_{out}  \\cdot k_{in} \\cdot k_{out}$"
      ],
      "metadata": {
        "id": "Ef_-IJ1jPELX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- $H_{in} = W_{in} = 11$\n",
        "- $k_{in} = k_{out} = 3$\n",
        "- $C_{in} = C_{out} = 16$\n",
        "\n",
        "Assume $H_{out} = W_{out} = 9$"
      ],
      "metadata": {
        "id": "DdwPkQkFPyg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\Rightarrow$ **FLOPS** $= C_{out} \\cdot W_{out} \\cdot H_{out}  \\cdot(2 k_{in} \\cdot k_{out} - 1) = 16 \\cdot 9^2(2 \\cdot 3^2 - 1) = 22032$\n"
      ],
      "metadata": {
        "id": "mhXSfqdKQhjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\Rightarrow$ **MAC** $= C_{out} \\cdot W_{out} \\cdot H_{out}  \\cdot k_{in} \\cdot k_{out} = 16 \\cdot 9^2 \\cdot 3^2 = 11664$"
      ],
      "metadata": {
        "id": "BkKCcQ0HP11j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b)**"
      ],
      "metadata": {
        "id": "3CHNaexpMKyU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only diffence between **b)** and **c)** is that in **b)** for every output 2D layer we compute 2D matrix elemetwise sum $C_{in}$ times after kernelwise convolutions"
      ],
      "metadata": {
        "id": "Zde5fFpZbOtS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**multiplications:** $C_{in} \\cdot C_{out} \\cdot W_{out} \\cdot H_{out}  \\cdot k_{in} \\cdot k_{out}$\n",
        "\n",
        "**summations:** $(C_{in} - 1) \\cdot  C_{out} \\cdot W_{out} \\cdot H_{out}  \\cdot (k_{in} \\cdot k_{out} - 1)$ "
      ],
      "metadata": {
        "id": "1KcLOnp2cbpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Let's translate in for conventional units:\n",
        "\n",
        "**FLOPS** $= C_{out} \\cdot W_{out} \\cdot H_{out}[C_{in} \\cdot(2 k_{in} \\cdot k_{out} - 1) - (k_{in} \\cdot k_{out} - 1)]$ $= C_{out} \\cdot W_{out} \\cdot H_{out}[k_{in} \\cdot k_{out}(2C_{in} - 1) - C_{in} + 1]$\n",
        "\n",
        "**MAC** $= C_{in} \\cdot C_{out} \\cdot W_{out} \\cdot H_{out}  \\cdot k_{in} \\cdot k_{out}$"
      ],
      "metadata": {
        "id": "oreYgWnKcI-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- $H_{in} = W_{in} = 11$\n",
        "- $k_{in} = k_{out} = 3$\n",
        "- $C_{in} = C_{out} = 16$\n",
        "\n",
        "Assume $H_{out} = W_{out} = 9$"
      ],
      "metadata": {
        "id": "-wUtDq2tRTbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\Rightarrow$ **FLOPS** $= C_{out} \\cdot W_{out} \\cdot H_{out}[k_{in} \\cdot k_{out}(2C_{in} - 1) - C_{in} + 1] = 16 \\cdot 9^2[3^2(2 \\cdot 16 - 1) - 16 + 1] = 342144$"
      ],
      "metadata": {
        "id": "2j52LONZRj4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\Rightarrow$ **MAC** $= C_{in} \\cdot C_{out} \\cdot W_{out} \\cdot H_{out}  \\cdot k_{in} \\cdot k_{out} =16^2 \\cdot 9^2 \\cdot 3^2 = 186624$"
      ],
      "metadata": {
        "id": "BbjfoEH0Ogme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4 [2 points]\n",
        "Assume that size of input image $x$ is $(3, 220, 220)$.\n",
        "\n",
        "Compute FLOP for BatchNorm2d(x)\n",
        "\n",
        "Note: Consider, that  FLOP(division operation) = 4."
      ],
      "metadata": {
        "id": "j-n7GCUy13e9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume, that batch size = 10"
      ],
      "metadata": {
        "id": "khVisSJ_sDQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean takes: $\\underbrace{4}_{division} + \\underbrace{220^2 - 1}_{2d \\space matrix \\space sum}$\n",
        "\n",
        "Std takes: $\\underbrace{4}_{\\sqrt{}} + \\underbrace{4}_{division} + \\underbrace{2 \\cdot 220^2}_{-\\mu \\space + squared} + \\underbrace{220^2 - 1}_{2d \\space matrix \\space sum} + \\underbrace{1}_{\\varepsilon}$\n",
        "\n",
        "In the end we subtract mean and divide by std and multiply and shift:$(\\underbrace{1}_{-\\mu} + \\underbrace{4}_{division} + \\underbrace{2}_{\\gamma + \\beta}) \\cdot 220^2$\n",
        "\n",
        "We computed batch-wise, now let's summarize:\n",
        "\n",
        "For every channel we compute our statistics:\n",
        "\n",
        "Channels num = $3$\n",
        "\n",
        "**FLOP** $= 3  \\cdot ((4 + 220^2 - 1) + (4 + 4 + 2 \\cdot 220^2 + 220^2 - 1 + 1) + (1 + 4 + 2) \\cdot 220^2)) = 5808000$"
      ],
      "metadata": {
        "id": "EFqiU6j913e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "3 * ((3 + 220**2) + (8 + 2 * 220**2) + (7 * 220**2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHOaqMbAIqdW",
        "outputId": "5fecbadc-4428-4a5e-972f-02c69ee769bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1452033"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision tensorly==0.4.5 flopco-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJBWTucf3p9s",
        "outputId": "a2a695d8-ce5f-4274-b6da-b089f5cdf581"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Collecting tensorly==0.4.5\n",
            "  Downloading tensorly-0.4.5.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting flopco-pytorch\n",
            "  Downloading flopco_pytorch-0.1.4-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly==0.4.5) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensorly==0.4.5) (1.4.1)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Building wheels for collected packages: tensorly\n",
            "  Building wheel for tensorly (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorly: filename=tensorly-0.4.5-py3-none-any.whl size=100163 sha256=cfd1b45b16a5af990604eb6cacc12da5cc5db538adc46edf5dd467fcb01bed5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/ed/36/493bba3faa150a1193eec864db4951355eb64659330cb00722\n",
            "Successfully built tensorly\n",
            "Installing collected packages: nose, tensorly, flopco-pytorch\n",
            "Successfully installed flopco-pytorch-0.1.4 nose-1.3.7 tensorly-0.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((1, 220, 220, 3))"
      ],
      "metadata": {
        "id": "ZU1CQjUg48IB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = nn.BatchNorm2d(num_features=220)"
      ],
      "metadata": {
        "id": "p7iyM_8r37dP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ord_stats = FlopCo(layer, x.shape, instances=[nn.BatchNorm2d])\n",
        "ord_stats.total_flops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEWH7FuX31Nr",
        "outputId": "76c2dee6-c9d5-4cc2-abc5-bd71d578ecf8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "580800"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5 [3 points]\n",
        " a) [1 point] Compute FLOP for Parametric ReLU (PReLU):\n",
        "\n",
        "$$\\operatorname{PReLU}\n",
        "\\left(y_{i}\\right)= \\begin{cases}y_{i}, & \\text { if } y_{i}>0 \\\\ a_{i} y_{i}, & \\text { if } y_{i} \\leq 0\\end{cases}$$"
      ],
      "metadata": {
        "id": "GLneX0DG0rTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR FORMULA HERE"
      ],
      "metadata": {
        "id": "X95-rZ6n0rTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " b) [1 point] Compute FLOP for Gaussian Error Linear Units function (GELU):\n",
        "\n",
        "$$\\operatorname{GELU}(x)=x * \\Phi(x) = 0.5 x\\left(1+\\tanh \\left(\\sqrt{2 / \\pi}\\left(x+0.044715 x^{3}\\right)\\right)\\right),$$\n",
        "\n",
        "where $\\Phi(x)$ - is the Cumulative Distribution Function for Gaussian Distribution.\n",
        "\n",
        "Note: consider, that $\\operatorname{FLOP}(\\operatorname{tanh}) = 60$."
      ],
      "metadata": {
        "id": "8mq007Vwl7XG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR FORMULA HERE"
      ],
      "metadata": {
        "id": "zQ8m14ZymtOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) [1 point] Compute FLOP for Softmax function:\n",
        "\n",
        "\n",
        "$$\\operatorname{Softmax}\\left(x_{i}\\right)=\\frac{\\exp \\left(x_{i}\\right)}{\\sum_{j} \\exp \\left(x_{j}\\right)}.$$\n",
        "\n",
        "Note: consider, that $\\operatorname{FLOP}(\\operatorname{exp}) = 40$."
      ],
      "metadata": {
        "id": "n6C5EMejmuMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR FORMULA HERE"
      ],
      "metadata": {
        "id": "kRmZyh216ne-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}