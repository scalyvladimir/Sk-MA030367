{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with NA values\n",
    "\n",
    "1. Impute with some statistical (reasonable) value.\n",
    "    - Statistic over feature. \n",
    "    > fill NA Age with mean Age\n",
    "    - Statistic over groupby feature. \n",
    "    > fill NA Age of Females with mean Age of Females\n",
    "2. Impute with anomalous value + creating indicator column (prefered for tree based methods).\n",
    "3. Other\n",
    "    - Leave them as is. \n",
    "    - Predict missing values based on other features (*typically* impractical).\n",
    "    - KNN based\n",
    "    - Drop (*typically* the worst option).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./ml\\ds/titanic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Passenger Class                       1309\n",
       "Name                                  1309\n",
       "Sex                                   1309\n",
       "Age                                   1046\n",
       "No of Siblings or Spouses on Board    1309\n",
       "No of Parents or Children on Board    1309\n",
       "Ticket Number                         1309\n",
       "Passenger Fare                        1308\n",
       "Cabin                                  295\n",
       "Port of Embarkation                   1307\n",
       "Life Boat                              486\n",
       "Survived                              1309\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, train_size=0.33, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Impute with different statistics.\n",
    "\n",
    "- Impute with some statistics of this particular feature:\n",
    "    - mean (average)\n",
    "    - median\n",
    "    - percentiles\n",
    "    - mode (most frequent). Also works for categorical features\n",
    "    \n",
    "- Impute with some statistics computed within categorical groups:\n",
    "    - Impute missing `Age` with average/median `Age` of a person of the same `Sex`\n",
    "    - Impute missing `Price` with the average/median Price of a item from the same `Category`\n",
    "    \n",
    "> Must be done with extreme **CAUTION**, otherwise easy to overfit.\n",
    "\n",
    "Imputation in **test** part of the data better be done based on statistics computed on **train**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.1 Statistic over the feature\n",
    "\n",
    "### Manual computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anvar/miniconda3/lib/python3.7/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "aver_age = df.Age.mean()\n",
    "\n",
    "df.Age = df.Age.fillna(aver_age)\n",
    "\n",
    "# Or if we have X_train, X_test\n",
    "\n",
    "aver_age = X_train.Age.mean()\n",
    "\n",
    "X_train.Age = X_train.Age.fillna(aver_age)\n",
    "X_test.Age = X_train.Age.fillna(aver_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sklearn.impute` to use with `sklearn.pipe.Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anvar/miniconda3/lib/python3.7/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/home/anvar/miniconda3/lib/python3.7/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "df.Age = imputer.fit_transform(df.Age.values.reshape(-1, 1))\n",
    "\n",
    "# Or if we have X_train, X_test\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(X_train.Age.values.reshape(-1, 1))\n",
    "\n",
    "X_train.Age = imputer.transform(X_train.Age.values.reshape(-1, 1))\n",
    "X_test.Age = imputer.transform(X_test.Age.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Statistics within groups\n",
    "\n",
    "### Manual computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aver_age_sex = df.groupby(['Sex'])['Age'].mean()\n",
    "\n",
    "df[df.Age.isna()].Age = df[df.Age.isna()].Sex.map(aver_age_sex)\n",
    "\n",
    "# Or if we have X_train, X_test\n",
    "\n",
    "aver_age_sex = X_train.groupby(['Sex'])['Age'].mean()\n",
    "\n",
    "X_train[X_train.Age.isna()].Age = X_train[X_train.Age.isna()].Sex.map(aver_age_sex)\n",
    "X_test[X_test.Age.isna()].Age = X_test[X_test.Age.isna()].Sex.map(aver_age_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `sklearn.impute` to use with `sklearn.pipe.Pipeline`\n",
    "\n",
    "requires writing a custom Imputer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, groupby_col, impute_col, agg):\n",
    "        \"\"\"Imputes missing values using groupby aggregated statistic.\n",
    "        \n",
    "        Parameters\n",
    "        ---\n",
    "        \n",
    "        groupby_col - str,\n",
    "            column to groupby over\n",
    "            \n",
    "        impute_col - str,\n",
    "            column to make imputation\n",
    "            \n",
    "        agg - function,\n",
    "            aggregation function\n",
    "        \"\"\"\n",
    "        self.groupby_col = groupby_col\n",
    "        self.impute_col = impute_col\n",
    "        self.agg = agg\n",
    "        self._mapper = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self._mapper = X.groupby(self.groupby_col)[self.impute_col].apply(self.agg)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X.loc[:, self.impute_col] = X[self.groupby_col].map(self._mapper)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anvar/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Statistic over the feature\n",
    "\n",
    "imputer = CustomImputer(groupby_col='Sex', impute_col='Age', agg=np.mean)\n",
    "\n",
    "df.Age = imputer.fit_transform(df)\n",
    "\n",
    "# Or if we have X_train, X_test\n",
    "\n",
    "imputer = CustomImputer(groupby_col='Sex', impute_col='Age', agg=np.mean)\n",
    "\n",
    "imputer.fit(X_train)\n",
    "\n",
    "X_train.Age = imputer.transform(X_train)\n",
    "X_test.Age = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create indicator column.\n",
    "\n",
    "Sometimes (often) missing value of some feature is itself a great signal. \n",
    "> Recall, `Life Boat` in Titanic dataset, the fact that the person have a NA value in this column means that he is most probably did not survived (otherwise is also true, those who have non NA Life Boat are most likely survived).\n",
    "\n",
    "This approach is especially useful if you use tree based methods.\n",
    "\n",
    "1. Impute NA values with some anomalous, impossible value, e.g. negative value for `Age`.\n",
    "2. Create an additional indicator column, 1 if value is missing and 0 otherwise.\n",
    "\n",
    "Alternitevely, IF most of the values are missing, you could simply create indicator column (and drop the original column).\n",
    "\n",
    "> Easier cross-validation, since we could do this preprocessing before `train-test` split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indicator column\n",
    "\n",
    "df['has_NA_Age'] = df.Age.isna().astype(int)\n",
    "\n",
    "# Fill missing values with impossible value for this feature\n",
    "\n",
    "df.Age.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Other\n",
    "\n",
    "## 3.1 Do not deal with them.\n",
    "\n",
    "Some of the modern implementations (e.g. catboost) will handle missing values for you. \n",
    "Typically, using one of the methods above, e.g. catboost uses two approaches:\n",
    "- “Min” — Missing values are processed as the minimum value (less than all other values) for the feature. It is guaranteed that a split that separates missing values from all other values is considered when selecting trees.\n",
    "- “Max” — Missing values are processed as the maximum value (greater than all other values) for the feature. It is guaranteed that a split that separates missing values from all other values is considered when selecting trees.\n",
    "\n",
    "from  https://catboost.ai/docs/concepts/input-data_custom-borders.html\n",
    "\n",
    "Both are versions of the `2. Create indicator column.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¯\\\\_(ツ)_/¯'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"¯\\_(ツ)_/¯\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Predict missing values based on other features (typically impractical)\n",
    "\n",
    "> The idea is to solve regression or classification problem but instead of original target variable use column with missing values. The problem is, it requires embedded cross-validation and goes far beyond this introductory course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Use similar observations (KNN)\n",
    "\n",
    "> Find k observations which has similar feature (and not NA in required column) representation and average over them.\n",
    "\n",
    "This option is similar to `1.2 Statistics within groups`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before imputation\n",
      " [[ 1.  2. nan]\n",
      " [ 3.  4.  3.]\n",
      " [nan  6.  5.]\n",
      " [ 8.  8. nan]]\n",
      "\n",
      "After imputation\n",
      " [[1.  2.  4. ]\n",
      " [3.  4.  3. ]\n",
      " [5.5 6.  5. ]\n",
      " [8.  8.  4. ]]\n"
     ]
    }
   ],
   "source": [
    "# Example from sklearn documentation\n",
    "\n",
    "X = np.array([[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, np.nan]])\n",
    "print('Before imputation\\n', X)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "X = imputer.fit_transform(X)\n",
    "print('\\nAfter imputation\\n', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Drop missing values.\n",
    "\n",
    "Rarely a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NA\n",
    "\n",
    "df.Age.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with `any` NA\n",
    "\n",
    "df.dropna(inplace=True, axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "I would personally recommend to use `2. Indicator column` approach almost always (or methods wich works with NA out of the box), but under certain circumstances other methods might work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
