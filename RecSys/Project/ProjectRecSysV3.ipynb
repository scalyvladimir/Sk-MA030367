{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zfbrvMoy9Ed",
    "outputId": "7a7e8dee-1a04-4cd7-b477-948617373a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Collecting polara\n",
      "  Cloning https://github.com/evfro/polara.git (to revision develop) to /private/var/folders/28/jnstkr6902l__8f0j4tmfrwm0000gn/T/pip-install-s_ymx9iv/polara_7646956d89514cfe8eb6dd54961d4b2f\n",
      "  Running command git clone --filter=blob:none -q https://github.com/evfro/polara.git /private/var/folders/28/jnstkr6902l__8f0j4tmfrwm0000gn/T/pip-install-s_ymx9iv/polara_7646956d89514cfe8eb6dd54961d4b2f\n",
      "  Running command git checkout -b develop --track origin/develop\n",
      "  Switched to a new branch 'develop'\n",
      "  Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n",
      "  Resolved https://github.com/evfro/polara.git to commit 4de4ca7d6f901e32f1e045f190bcb09587162397\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/homebrew/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Jd1axtgLy9Id"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import polara\n",
    "from polara import get_movielens_data\n",
    "from polara.preprocessing.dataframes import leave_one_out, reindex\n",
    "\n",
    "from dataprep import transform_indices\n",
    "from evaluation import topn_recommendations, model_evaluate, downvote_seen_items\n",
    "\n",
    "from polara.lib.tensor import hooi\n",
    "from polara.lib.sparse import tensor_outer_at\n",
    "\n",
    "from sa_hooi import sa_hooi, form_attention_matrix, get_scaling_weights, generate_position_projector\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BDtwh0bdy9Mk"
   },
   "outputs": [],
   "source": [
    "def full_preproccessing():\n",
    "    data = get_movielens_data(include_time=True)\n",
    "    test_timepoint = data['timestamp'].quantile(\n",
    "    q=0.9, interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    test_data_ = data.query('timestamp >= @test_timepoint')\n",
    "    train_data_ = data.query(\n",
    "    'userid not in @test_data_.userid.unique() and timestamp < @test_timepoint'\n",
    "    )\n",
    "    \n",
    "    training, data_index = transform_indices(train_data_.copy(), 'userid', 'movieid')\n",
    "    test_data = reindex(test_data_, data_index['items'])\n",
    "\n",
    "    testset_, holdout_ = leave_one_out(\n",
    "    test_data, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "    testset_valid_, holdout_valid_ = leave_one_out(\n",
    "        testset_, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "\n",
    "    test_users_val = np.intersect1d(testset_valid_.userid.unique(), holdout_valid_.userid.unique())\n",
    "    testset_valid = testset_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "    holdout_valid = holdout_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "\n",
    "    test_users = np.intersect1d(testset_valid_.userid.unique(), holdout_valid_.userid.unique())\n",
    "    testset = testset_.query('userid in @test_users').sort_values('userid')\n",
    "    holdout = holdout_.query('userid in @test_users').sort_values('userid')\n",
    "\n",
    "\n",
    "    assert holdout_valid.set_index('userid')['timestamp'].ge(\n",
    "        testset_valid\n",
    "        .groupby('userid')\n",
    "        ['timestamp'].max()\n",
    "    ).all()\n",
    "\n",
    "    data_description = dict(\n",
    "        users = data_index['users'].name,\n",
    "        items = data_index['items'].name,\n",
    "        feedback = 'rating',\n",
    "        n_users = len(data_index['users']),\n",
    "        n_items = len(data_index['items']),\n",
    "        n_ratings = training['rating'].nunique(),\n",
    "        min_rating = training['rating'].min()\n",
    "        #test_users_val = holdout_valid[data_index['users'].name].drop_duplicates().values,\n",
    "        #test_users_test = holdout[data_index['users'].name].drop_duplicates().values\n",
    "    )\n",
    "\n",
    "    return training, testset_valid, holdout_valid, testset, holdout, data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmYMpvcBy9QZ",
    "outputId": "6dfec15f-9e51-4ef5-afd6-4dc14dddf98d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 113 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, testset_valid, holdout_valid, testset, holdout, data_description = full_preproccessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SM-pkXQx1GwO"
   },
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "\n",
    "def tf_model_build(config, data, data_description, attention_matrix=np.array([]), exp_decay = False, decay=1):\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    idx = data[[userid, itemid, feedback]].values\n",
    "    idx[:, -1] = idx[:, -1] - data_description['min_rating'] # works only for integer ratings!\n",
    "    val = np.ones(idx.shape[0], dtype='f8')\n",
    "    \n",
    "    n_users = data_description[\"n_users\"]\n",
    "    n_items = data_description[\"n_items\"]\n",
    "    n_ratings = data_description[\"n_ratings\"]\n",
    "    shape = (n_users, n_items, n_ratings)\n",
    "    core_shape = config['mlrank']\n",
    "    num_iters = config[\"num_iters\"]\n",
    "    \n",
    "    if (attention_matrix.shape[0] == 0):\n",
    "        attention_matrix = form_attention_matrix(\n",
    "            data_description['n_ratings'],\n",
    "            **config['params'],\n",
    "            format = 'csr'\n",
    "        )\n",
    "\n",
    "    item_popularity = (\n",
    "        data[itemid]\n",
    "        .value_counts(sort=False)\n",
    "        .reindex(range(n_items))\n",
    "        .fillna(1)\n",
    "        .values\n",
    "    )\n",
    "    scaling_weights = get_scaling_weights(item_popularity, scaling=config[\"scaling\"])\n",
    "\n",
    "    with io.capture_output() as captured:\n",
    "        u0, u1, u2 = sa_hooi(\n",
    "            idx, val, shape, config[\"mlrank\"],\n",
    "            attention_matrix = attention_matrix,\n",
    "            scaling_weights = scaling_weights,\n",
    "            max_iters = config[\"num_iters\"],\n",
    "            parallel_ttm = False,\n",
    "            randomized = config[\"randomized\"],\n",
    "            growth_tol = config[\"growth_tol\"],\n",
    "            seed = config[\"seed\"],\n",
    "            iter_callback = None,\n",
    "        )\n",
    "    \n",
    "    return u0, u1, u2, attention_matrix    \n",
    "    \n",
    "config = {\n",
    "    \"scaling\": 1,\n",
    "    \"mlrank\": (30, 30, 5),\n",
    "    \"n_ratings\": data_description['n_ratings'],\n",
    "    \"num_iters\": 5,\n",
    "    \"params\": None,\n",
    "    \"randomized\": True,\n",
    "    \"growth_tol\": 1e-4,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "\n",
    "def tf_scoring(params, data, data_description, context=[\"3+4+5\"]):\n",
    "    user_factors, item_factors, feedback_factors, attention_matrix = params\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    data = data.sort_values(userid)\n",
    "    useridx = data[userid]\n",
    "    \n",
    "    n_users = useridx.nunique()\n",
    "    n_items = data_description['n_items']\n",
    "    n_ratings = data_description['n_ratings']\n",
    "    \n",
    "    scores = np.zeros((n_users, n_items))\n",
    "    inv_attention = np.linalg.inv(attention_matrix.A)\n",
    "    for i, u in tqdm(enumerate(np.unique(useridx))):\n",
    "        data_u = data[data.userid==u]\n",
    "        P = csr_matrix((np.ones(data_u.shape[0]), (data_u[itemid].values, data_u[feedback].values - data_description['min_rating'])), (n_items, n_ratings))\n",
    "        res = item_factors @ (item_factors.T @ (P @ (attention_matrix @ (feedback_factors @ (inv_attention.T @ feedback_factors).T))))\n",
    "        if (context == \"5\"):\n",
    "            scores[i] = np.sum(res[:, -1:], axis=1)\n",
    "        elif (context == \"4+5\"):\n",
    "            scores[i] = np.sum(res[:, -2:], axis=1)\n",
    "        elif (context == \"3+4+5\"):\n",
    "            scores[i] = np.sum(res[:, -3:], axis=1)\n",
    "        elif (context == \"2+3+4+5\"):\n",
    "            scores[i] = np.sum(res[:, -4:], axis=1)\n",
    "        elif (context == \"3+4+5-2-1\"):\n",
    "            scores[i] = np.sum(res[:, 2:], axis=1) - np.sum(res[:, :2], axis=1)\n",
    "        \n",
    "    return scores\n",
    "\n",
    "def model_evaluate(recommended_items, holdout, holdout_description, alpha=3, topn=10):\n",
    "    itemid = holdout_description['items']\n",
    "    rateid = holdout_description['feedback']\n",
    "    holdout_items = holdout[itemid].values\n",
    "    assert recommended_items.shape[0] == len(holdout_items)\n",
    "    hits_mask = recommended_items[:, :topn] == holdout_items.reshape(-1, 1)\n",
    "    # HR calculation\n",
    "    hr = np.mean(hits_mask.any(axis=1))\n",
    "    # MRR calculation\n",
    "    n_test_users = recommended_items.shape[0]\n",
    "    hit_rank = np.where(hits_mask)[1] + 1.0\n",
    "    mrr = np.sum(1 / hit_rank) / n_test_users\n",
    "    # DCG calculation\n",
    "    pos_mask = (holdout[rateid] >= alpha).values\n",
    "    neg_mask = (holdout[rateid] < alpha).values\n",
    "    pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "    neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "    ndcg = np.sum(1 / np.log2(pos_hit_rank+1)) / n_test_users\n",
    "    ndcl = np.sum(1 / np.log2(neg_hit_rank+1)) / n_test_users\n",
    "    # coverage calculation\n",
    "    n_items = holdout_description['n_items']\n",
    "    cov = np.unique(recommended_items).size / n_items\n",
    "    return hr, mrr, cov, ndcg, ndcl\n",
    "\n",
    "def make_prediction(tf_scores, holdout, data_description, mode, context=\"\"):\n",
    "    if (mode):\n",
    "        print(f\"for context {context} evaluation:\")\n",
    "    for n in [5, 10, 20]:\n",
    "        tf_recs = topn_recommendations(tf_scores, n)\n",
    "        hr, mrr, cov, dcg, dcl = model_evaluate(tf_recs, holdout_valid, data_description, topn=n)\n",
    "        print(f\"Test : HR@{n} = {hr:.4f}, MRR@{n} = {mrr:.4f}, Coverage@{n} = {cov:.4f}, nDCG@{n} = {dcg}, nDCL@{n} = {dcl}\")\n",
    "        if (n == 10):\n",
    "            mrr10 = mrr\n",
    "    return mrr10\n",
    "\n",
    "def valid_mlrank(mlrank):\n",
    "    '''\n",
    "    Only allow ranks that are suitable for truncated SVD computations\n",
    "    on unfolded compressed tensor (the result of ttm product in HOOI).\n",
    "    '''\n",
    "    r1, r2, r3 = mlrank\n",
    "    return r1*r2 > r3 and r1*r3 > r2 and r2*r3 > r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3p0AyeCf3QVU"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from polara.evaluation.pipelines import random_grid\n",
    "\n",
    "def full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix):\n",
    "\n",
    "    config[\"mlrank\"] = (30, 30, 5)\n",
    "    print(\"Starting pipeline...\")\n",
    "    print(\"Training with different context in progress...\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "    best_mrr_context = \"3+4+5\"\n",
    "    best_mrr = 0.0\n",
    "    for context in [\"5\", \"4+5\", \"3+4+5\", \"2+3+4+5\", \"3+4+5-2-1\"]:\n",
    "        tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "        seen_data = testset_valid\n",
    "        tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "        downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "        cur_mrr = make_prediction(tf_scores, holdout_valid, data_description, \"Validation\", context)\n",
    "        print(\"------------------------------------------------------\")\n",
    "        if (cur_mrr > best_mrr):\n",
    "            best_mrr = cur_mrr\n",
    "            best_mrr_context = context\n",
    "\n",
    "    best_mrr_context = \"3+4+5\" # intuitively this is better \n",
    "    print(f\"Tuning model with context {best_mrr_context}...\")\n",
    "\n",
    "    tf_hyper = {\n",
    "    'r1': range(30, 56, 5),\n",
    "    'r2': range(30, 56, 5),\n",
    "    'r3': range(5, 6, 5),\n",
    "    }\n",
    "\n",
    "    grid, param_names = random_grid(tf_hyper, n=0)\n",
    "    tf_grid = [tuple(mlrank) for mlrank in grid if valid_mlrank(mlrank)]\n",
    "\n",
    "    hr_tf = {}\n",
    "    mrr_tf = {}\n",
    "    cov_tf = {}\n",
    "    for mlrank in tqdm(tf_grid):\n",
    "        with io.capture_output() as captured:\n",
    "            config['mlrank'] = mlrank\n",
    "            tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "            tf_scores = tf_scoring(tf_params, seen_data, data_description, best_mrr_context)\n",
    "            downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "            tf_recs = topn_recommendations(tf_scores, topn=10)\n",
    "            hr, mrr, cov, dcg, dcl = model_evaluate(tf_recs, holdout_valid, data_description, topn=10)\n",
    "            hr_tf[mlrank] = hr\n",
    "            mrr_tf[mlrank] = mrr\n",
    "            cov_tf[mlrank] = cov\n",
    "\n",
    "    print(f'Best HR={pd.Series(hr_tf).max():.4f} achieved with mlrank={pd.Series(hr_tf).idxmax()}')\n",
    "    print(f'Best MRR={pd.Series(mrr_tf).max():.4f} achieved with mlrank={pd.Series(mrr_tf).idxmax()}')\n",
    "    print(f'COV={pd.Series(cov_tf)[pd.Series(mrr_tf).idxmax()]:.4f} (based on best HR value)')\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(\"Evaluation of the best model on test holdout in progress...\")\n",
    "    \n",
    "    config[\"mlrank\"] = pd.Series(mrr_tf).idxmax()\n",
    "    tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, best_mrr_context)\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr = make_prediction(tf_scores, holdout, data_description, \"Test\", best_mrr_context)\n",
    "    print(\"Pipeline ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAJa3SH0_RNF"
   },
   "source": [
    "## Linear attention, decay factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_attentions_list = [\n",
    "    {'decay_factor': 1, 'exponential_decay': False, 'reverse': True},\n",
    "    {'decay_factor': 1, 'exponential_decay': False, 'reverse': False},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1238.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0361, MRR@5 == 0.0180, Coverage@5 = 0.0883\n",
      "Validation : HR@10 = 0.0563, MRR@10 == 0.0204, Coverage@10 = 0.1315\n",
      "Validation : HR@20 = 0.1020, MRR@20 == 0.0235, Coverage@20 = 0.1829\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1242.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0255, MRR@5 == 0.0139, Coverage@5 = 0.0913\n",
      "Validation : HR@10 = 0.0598, MRR@10 == 0.0181, Coverage@10 = 0.1279\n",
      "Validation : HR@20 = 0.1011, MRR@20 == 0.0211, Coverage@20 = 0.1766\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1197.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0163, Coverage@5 = 0.0971\n",
      "Validation : HR@10 = 0.0633, MRR@10 == 0.0206, Coverage@10 = 0.1329\n",
      "Validation : HR@20 = 0.1143, MRR@20 == 0.0241, Coverage@20 = 0.1772\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1236.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0165, Coverage@5 = 0.0977\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0206, Coverage@10 = 0.1337\n",
      "Validation : HR@20 = 0.1099, MRR@20 == 0.0240, Coverage@20 = 0.1824\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1108.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0281, MRR@5 == 0.0147, Coverage@5 = 0.0944\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0190, Coverage@10 = 0.1301\n",
      "Validation : HR@20 = 0.1064, MRR@20 == 0.0220, Coverage@20 = 0.1788\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [23:16<00:00, 38.80s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0792 achieved with mlrank=(45, 55, 5)\n",
      "Best MRR=0.0279 achieved with mlrank=(45, 55, 5)\n",
      "COV=0.1615 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1091.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0281, MRR@5 == 0.0124, Coverage@5 = 0.1199\n",
      "Test : HR@10 = 0.0580, MRR@10 == 0.0164, Coverage@10 = 0.1623\n",
      "Test : HR@20 = 0.0950, MRR@20 == 0.0189, Coverage@20 = 0.2209\n",
      "Pipeline ended.\n",
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1201.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0281, MRR@5 == 0.0170, Coverage@5 = 0.1073\n",
      "Validation : HR@10 = 0.0484, MRR@10 == 0.0197, Coverage@10 = 0.1513\n",
      "Validation : HR@20 = 0.0906, MRR@20 == 0.0226, Coverage@20 = 0.2132\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1186.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0281, MRR@5 == 0.0181, Coverage@5 = 0.1062\n",
      "Validation : HR@10 = 0.0598, MRR@10 == 0.0220, Coverage@10 = 0.1488\n",
      "Validation : HR@20 = 0.1108, MRR@20 == 0.0257, Coverage@20 = 0.2036\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1405.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0317, MRR@5 == 0.0184, Coverage@5 = 0.1136\n",
      "Validation : HR@10 = 0.0633, MRR@10 == 0.0225, Coverage@10 = 0.1543\n",
      "Validation : HR@20 = 0.1170, MRR@20 == 0.0261, Coverage@20 = 0.2094\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1272.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0281, MRR@5 == 0.0180, Coverage@5 = 0.1172\n",
      "Validation : HR@10 = 0.0633, MRR@10 == 0.0227, Coverage@10 = 0.1574\n",
      "Validation : HR@20 = 0.1161, MRR@20 == 0.0263, Coverage@20 = 0.2151\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1273.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0264, MRR@5 == 0.0166, Coverage@5 = 0.1128\n",
      "Validation : HR@10 = 0.0554, MRR@10 == 0.0204, Coverage@10 = 0.1527\n",
      "Validation : HR@20 = 0.1020, MRR@20 == 0.0236, Coverage@20 = 0.2105\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:38<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0783 achieved with mlrank=(55, 50, 5)\n",
      "Best MRR=0.0291 achieved with mlrank=(55, 50, 5)\n",
      "COV=0.1766 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1060.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0281, MRR@5 == 0.0136, Coverage@5 = 0.1307\n",
      "Test : HR@10 = 0.0545, MRR@10 == 0.0169, Coverage@10 = 0.1774\n",
      "Test : HR@20 = 0.0994, MRR@20 == 0.0198, Coverage@20 = 0.2415\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "for params in linear_attentions_list:\n",
    "    \n",
    "    config[\"params\"] = params\n",
    "    \n",
    "    full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=np.array([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHY4qoqt_aEi"
   },
   "source": [
    "## Exponential attention, decay factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_attentions_list = [\n",
    "    {'decay_factor': 1, 'exponential_decay': True, 'reverse': True},\n",
    "    {'decay_factor': 1, 'exponential_decay': True, 'reverse': False}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1346.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0162, Coverage@5 = 0.0754\n",
      "Validation : HR@10 = 0.0431, MRR@10 == 0.0180, Coverage@10 = 0.1111\n",
      "Validation : HR@20 = 0.0853, MRR@20 == 0.0207, Coverage@20 = 0.1565\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1391.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0133, Coverage@5 = 0.0779\n",
      "Validation : HR@10 = 0.0545, MRR@10 == 0.0166, Coverage@10 = 0.1092\n",
      "Validation : HR@20 = 0.0897, MRR@20 == 0.0188, Coverage@20 = 0.1538\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1387.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0264, MRR@5 == 0.0158, Coverage@5 = 0.0817\n",
      "Validation : HR@10 = 0.0519, MRR@10 == 0.0193, Coverage@10 = 0.1136\n",
      "Validation : HR@20 = 0.0959, MRR@20 == 0.0222, Coverage@20 = 0.1538\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1311.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0264, MRR@5 == 0.0165, Coverage@5 = 0.0820\n",
      "Validation : HR@10 = 0.0536, MRR@10 == 0.0201, Coverage@10 = 0.1142\n",
      "Validation : HR@20 = 0.0950, MRR@20 == 0.0228, Coverage@20 = 0.1554\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1171.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0211, MRR@5 == 0.0133, Coverage@5 = 0.0795\n",
      "Validation : HR@10 = 0.0501, MRR@10 == 0.0171, Coverage@10 = 0.1109\n",
      "Validation : HR@20 = 0.0906, MRR@20 == 0.0199, Coverage@20 = 0.1543\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:48<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0721 achieved with mlrank=(50, 55, 5)\n",
      "Best MRR=0.0259 achieved with mlrank=(55, 55, 5)\n",
      "COV=0.1334 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1035.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0308, MRR@5 == 0.0147, Coverage@5 = 0.1021\n",
      "Test : HR@10 = 0.0519, MRR@10 == 0.0173, Coverage@10 = 0.1343\n",
      "Test : HR@20 = 0.0932, MRR@20 == 0.0201, Coverage@20 = 0.1843\n",
      "Pipeline ended.\n",
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1282.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0273, MRR@5 == 0.0150, Coverage@5 = 0.1078\n",
      "Validation : HR@10 = 0.0466, MRR@10 == 0.0175, Coverage@10 = 0.1521\n",
      "Validation : HR@20 = 0.0765, MRR@20 == 0.0194, Coverage@20 = 0.2135\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1282.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0273, MRR@5 == 0.0155, Coverage@5 = 0.1040\n",
      "Validation : HR@10 = 0.0563, MRR@10 == 0.0192, Coverage@10 = 0.1450\n",
      "Validation : HR@20 = 0.0985, MRR@20 == 0.0221, Coverage@20 = 0.1981\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1218.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0162, Coverage@5 = 0.1114\n",
      "Validation : HR@10 = 0.0580, MRR@10 == 0.0197, Coverage@10 = 0.1554\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0228, Coverage@20 = 0.2085\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1191.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0162, Coverage@5 = 0.1147\n",
      "Validation : HR@10 = 0.0589, MRR@10 == 0.0200, Coverage@10 = 0.1574\n",
      "Validation : HR@20 = 0.1064, MRR@20 == 0.0234, Coverage@20 = 0.2138\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1139.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0317, MRR@5 == 0.0163, Coverage@5 = 0.1073\n",
      "Validation : HR@10 = 0.0519, MRR@10 == 0.0189, Coverage@10 = 0.1469\n",
      "Validation : HR@20 = 0.0932, MRR@20 == 0.0218, Coverage@20 = 0.2072\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [04:02<00:00,  6.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0712 achieved with mlrank=(55, 45, 5)\n",
      "Best MRR=0.0260 achieved with mlrank=(55, 45, 5)\n",
      "COV=0.1678 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1129.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0229, MRR@5 == 0.0121, Coverage@5 = 0.1241\n",
      "Test : HR@10 = 0.0493, MRR@10 == 0.0157, Coverage@10 = 0.1673\n",
      "Test : HR@20 = 0.1003, MRR@20 == 0.0191, Coverage@20 = 0.2261\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "for params in exponential_attentions_list:\n",
    "    \n",
    "    config[\"params\"] = params\n",
    "    \n",
    "    full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=np.array([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZJWFtvA_fMT"
   },
   "source": [
    "## Eucledian distance attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x9NOoGl7_jYO"
   },
   "outputs": [],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        eucl_matrix[i, j] = abs(i - j) / np.exp(abs(i - j)) if i != j else 5 + 1e-2\n",
    "        \n",
    "a = np.linalg.cholesky(eucl_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.01      , 0.36787944, 0.27067057, 0.14936121, 0.07326256],\n",
       "       [0.36787944, 5.01      , 0.36787944, 0.27067057, 0.14936121],\n",
       "       [0.27067057, 0.36787944, 5.01      , 0.36787944, 0.27067057],\n",
       "       [0.14936121, 0.27067057, 0.36787944, 5.01      , 0.36787944],\n",
       "       [0.07326256, 0.14936121, 0.27067057, 0.36787944, 5.01      ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eucl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1284.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0192, Coverage@5 = 0.1051\n",
      "Validation : HR@10 = 0.0554, MRR@10 == 0.0224, Coverage@10 = 0.1458\n",
      "Validation : HR@20 = 0.0941, MRR@20 == 0.0251, Coverage@20 = 0.2044\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1122.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0273, MRR@5 == 0.0175, Coverage@5 = 0.1073\n",
      "Validation : HR@10 = 0.0607, MRR@10 == 0.0218, Coverage@10 = 0.1439\n",
      "Validation : HR@20 = 0.1020, MRR@20 == 0.0247, Coverage@20 = 0.2008\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1316.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0188, Coverage@5 = 0.1114\n",
      "Validation : HR@10 = 0.0642, MRR@10 == 0.0233, Coverage@10 = 0.1483\n",
      "Validation : HR@20 = 0.1108, MRR@20 == 0.0265, Coverage@20 = 0.2066\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1080.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0009, MRR@5 == 0.0003, Coverage@5 = 0.1620\n",
      "Validation : HR@10 = 0.0009, MRR@10 == 0.0003, Coverage@10 = 0.2325\n",
      "Validation : HR@20 = 0.0053, MRR@20 == 0.0006, Coverage@20 = 0.3254\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1037.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0009, MRR@5 == 0.0003, Coverage@5 = 0.1631\n",
      "Validation : HR@10 = 0.0009, MRR@10 == 0.0003, Coverage@10 = 0.2308\n",
      "Validation : HR@20 = 0.0044, MRR@20 == 0.0005, Coverage@20 = 0.3252\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:51<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0800 achieved with mlrank=(50, 50, 5)\n",
      "Best MRR=0.0296 achieved with mlrank=(50, 50, 5)\n",
      "COV=0.1766 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1043.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0317, MRR@5 == 0.0143, Coverage@5 = 0.1285\n",
      "Test : HR@10 = 0.0589, MRR@10 == 0.0177, Coverage@10 = 0.1769\n",
      "Test : HR@20 = 0.0967, MRR@20 == 0.0201, Coverage@20 = 0.2358\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating distribution attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.056644931644931645,\n",
       " 0.10500693000693001,\n",
       " 0.25943898443898444,\n",
       " 0.3442087192087192,\n",
       " 0.2347004347004347]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_dist = []\n",
    "\n",
    "total_cnt = training.shape[0]\n",
    "\n",
    "for i in range(5):\n",
    "    val = training.query(f'rating == {i + 1}').count()[0] / total_cnt\n",
    "    \n",
    "    rating_dist.append(val)\n",
    "\n",
    "rating_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1 , 0.05, 0.17, 0.22, 0.15],\n",
       "       [0.05, 1.1 , 0.13, 0.19, 0.11],\n",
       "       [0.17, 0.13, 1.1 , 0.08, 0.02],\n",
       "       [0.22, 0.19, 0.08, 1.1 , 0.1 ],\n",
       "       [0.15, 0.11, 0.02, 0.1 , 1.1 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rat_dist_matrix, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e-05,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.39343845e-02,  1.00000000e-05,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.57865247e-01,  1.19666749e-01,  1.00000000e-05,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.05660310e-01,  1.71084548e-01,  2.42154277e-02,\n",
       "         1.00000000e-05,  0.00000000e+00],\n",
       "       [ 1.42079211e-01,  1.02755253e-01, -1.02838852e-02,\n",
       "         5.08948653e-02,  1.00000000e-05]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        diff = abs(rating_dist[i] - rating_dist[j])\n",
    "        rat_dist_matrix[i, j] = diff / np.exp(diff) if i != j else 1. + 1e-1\n",
    "        \n",
    "a = np.linalg.cholesky(rat_dist_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1578.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0164, Coverage@5 = 0.0949, nDCG@5 = 0.01974361059223822, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0554, MRR@10 = 0.0195, Coverage@10 = 0.1337, nDCG@10 = 0.027115814538717472, nDCL@10 = 0.0005780450156306099\n",
      "Test : HR@20 = 0.0880, MRR@20 = 0.0217, Coverage@20 = 0.1796, nDCG@20 = 0.034121561049943884, nDCL@20 = 0.0017234280095878207\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1228.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0317, MRR@5 = 0.0188, Coverage@5 = 0.0988, nDCG@5 = 0.021991341338205694, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0598, MRR@10 = 0.0226, Coverage@10 = 0.1309, nDCG@10 = 0.030445577120236732, nDCL@10 = 0.0006064560426045343\n",
      "Test : HR@20 = 0.0950, MRR@20 = 0.0250, Coverage@20 = 0.1772, nDCG@20 = 0.03823413443949537, nDCL@20 = 0.0017425388095942825\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1367.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0352, MRR@5 = 0.0207, Coverage@5 = 0.0993, nDCG@5 = 0.0242442932393885, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0642, MRR@10 = 0.0245, Coverage@10 = 0.1315, nDCG@10 = 0.03301091015579248, nDCL@10 = 0.0006064560426045343\n",
      "Test : HR@20 = 0.1047, MRR@20 = 0.0273, Coverage@20 = 0.1777, nDCG@20 = 0.0418450635437097, nDCL@20 = 0.0019450015583606138\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1364.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0334, MRR@5 = 0.0205, Coverage@5 = 0.1007, nDCG@5 = 0.023644055214153612, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0624, MRR@10 = 0.0245, Coverage@10 = 0.1304, nDCG@10 = 0.03225564365276897, nDCL@10 = 0.0008808084437413651\n",
      "Test : HR@20 = 0.1038, MRR@20 = 0.0273, Coverage@20 = 0.1769, nDCG@20 = 0.0413107945521808, nDCL@20 = 0.0022137280911385345\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1268.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0325, MRR@5 = 0.0203, Coverage@5 = 0.1004, nDCG@5 = 0.02330381527815138, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0624, MRR@10 = 0.0244, Coverage@10 = 0.1304, nDCG@10 = 0.032442689825717075, nDCL@10 = 0.0006265737680000391\n",
      "Test : HR@20 = 0.1029, MRR@20 = 0.0272, Coverage@20 = 0.1769, nDCG@20 = 0.04104534979727037, nDCL@20 = 0.002209530709621398\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:40<00:00,  6.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0800 achieved with mlrank=(45, 45, 5)\n",
      "Best MRR=0.0279 achieved with mlrank=(40, 45, 5)\n",
      "COV=0.1560 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1024.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0000, MRR@5 = 0.0000, Coverage@5 = 0.1161, nDCG@5 = 0.0, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0000, MRR@10 = 0.0000, Coverage@10 = 0.1549, nDCG@10 = 0.0, nDCL@10 = 0.0\n",
      "Test : HR@20 = 0.0000, MRR@20 = 0.0000, Coverage@20 = 0.2077, nDCG@20 = 0.0, nDCL@20 = 0.0\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigonometry scale attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_score(x, func=None):\n",
    "    \n",
    "    if func is None:\n",
    "        func = np.arctan\n",
    "    \n",
    "    return func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eucl_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a8ebc25ca6c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meucl_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eucl_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "np.round(eucl_matrix, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        \n",
    "        k, l = rescale_score(i + 1), rescale_score(j + 1)\n",
    "        \n",
    "        diff = abs(k - l)\n",
    "        \n",
    "        eucl_matrix[i, j] = diff / np.exp(diff) if i != j else 5 + 1e-2\n",
    "        \n",
    "a = np.linalg.cholesky(eucl_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1441.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0343, MRR@5 == 0.0208, Coverage@5 = 0.1048\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0244, Coverage@10 = 0.1461\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0271, Coverage@20 = 0.2014\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1129.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0183, Coverage@5 = 0.1103\n",
      "Validation : HR@10 = 0.0633, MRR@10 == 0.0228, Coverage@10 = 0.1475\n",
      "Validation : HR@20 = 0.1108, MRR@20 == 0.0260, Coverage@20 = 0.2003\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1357.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0325, MRR@5 == 0.0190, Coverage@5 = 0.1111\n",
      "Validation : HR@10 = 0.0730, MRR@10 == 0.0243, Coverage@10 = 0.1527\n",
      "Validation : HR@20 = 0.1258, MRR@20 == 0.0277, Coverage@20 = 0.2047\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1302.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0369, MRR@5 == 0.0198, Coverage@5 = 0.1150\n",
      "Validation : HR@10 = 0.0704, MRR@10 == 0.0242, Coverage@10 = 0.1541\n",
      "Validation : HR@20 = 0.1249, MRR@20 == 0.0278, Coverage@20 = 0.2096\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1127.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0009, MRR@5 == 0.0003, Coverage@5 = 0.1653\n",
      "Validation : HR@10 = 0.0018, MRR@10 == 0.0004, Coverage@10 = 0.2360\n",
      "Validation : HR@20 = 0.0026, MRR@20 == 0.0005, Coverage@20 = 0.3249\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:58<00:00,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0844 achieved with mlrank=(50, 50, 5)\n",
      "Best MRR=0.0303 achieved with mlrank=(50, 50, 5)\n",
      "COV=0.1750 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1045.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0237, MRR@5 == 0.0103, Coverage@5 = 0.1287\n",
      "Test : HR@10 = 0.0589, MRR@10 == 0.0150, Coverage@10 = 0.1744\n",
      "Test : HR@20 = 0.0994, MRR@20 == 0.0177, Coverage@20 = 0.2338\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_and_rescale_score(x, func=None):\n",
    "    \n",
    "    if func is None:\n",
    "        func = np.arctan\n",
    "    \n",
    "    return func(x - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0.],\n",
       "       [0., 1., 1., 1., 0.],\n",
       "       [0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.75657241 0.47457495 0.34571609 0.31110998]\n",
      " [0.75657241 1.         0.56009915 0.38898453 0.34571609]\n",
      " [0.47457495 0.56009915 1.         0.56009915 0.47457495]\n",
      " [0.34571609 0.38898453 0.56009915 1.         0.75657241]\n",
      " [0.31110998 0.34571609 0.47457495 0.75657241 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        \n",
    "        k, l = center_and_rescale_score(i + 1), center_and_rescale_score(j + 1)\n",
    "        \n",
    "        diff = abs(k - l)\n",
    "        \n",
    "        eucl_matrix[i, j] = 1 / (diff + 1)\n",
    "\n",
    "similarity = eucl_matrix\n",
    "        \n",
    "print(similarity)\n",
    "    \n",
    "a = np.linalg.cholesky(similarity)        \n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1482.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0190, Coverage@5 = 0.1111\n",
      "Validation : HR@10 = 0.0528, MRR@10 == 0.0222, Coverage@10 = 0.1530\n",
      "Validation : HR@20 = 0.0871, MRR@20 == 0.0245, Coverage@20 = 0.2168\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1424.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0281, MRR@5 == 0.0192, Coverage@5 = 0.1103\n",
      "Validation : HR@10 = 0.0598, MRR@10 == 0.0235, Coverage@10 = 0.1505\n",
      "Validation : HR@20 = 0.1108, MRR@20 == 0.0270, Coverage@20 = 0.2039\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1415.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0197, Coverage@5 = 0.1139\n",
      "Validation : HR@10 = 0.0686, MRR@10 == 0.0246, Coverage@10 = 0.1552\n",
      "Validation : HR@20 = 0.1161, MRR@20 == 0.0279, Coverage@20 = 0.2110\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1366.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0187, Coverage@5 = 0.1164\n",
      "Validation : HR@10 = 0.0677, MRR@10 == 0.0239, Coverage@10 = 0.1596\n",
      "Validation : HR@20 = 0.1152, MRR@20 == 0.0272, Coverage@20 = 0.2138\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1312.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0180, Coverage@5 = 0.1109\n",
      "Validation : HR@10 = 0.0572, MRR@10 == 0.0217, Coverage@10 = 0.1527\n",
      "Validation : HR@20 = 0.1099, MRR@20 == 0.0253, Coverage@20 = 0.2116\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:38<00:00,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0827 achieved with mlrank=(50, 50, 5)\n",
      "Best MRR=0.0293 achieved with mlrank=(55, 50, 5)\n",
      "COV=0.1816 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1105.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0246, MRR@5 == 0.0129, Coverage@5 = 0.1312\n",
      "Test : HR@10 = 0.0554, MRR@10 == 0.0168, Coverage@10 = 0.1816\n",
      "Test : HR@20 = 0.0985, MRR@20 == 0.0198, Coverage@20 = 0.2454\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional prob attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 2')\n",
    "users = train_new_part.userid.unique()\n",
    "count12_tot = 0\n",
    "count12_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "     count12_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count12_loc += 1\n",
    "  count12_tot += count12_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count13_tot = 0\n",
    "count13_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "     count13_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count13_loc += 1\n",
    "  count13_tot += count13_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count14_tot = 0\n",
    "count14_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count14_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count14_loc += 1\n",
    "  count14_tot += count14_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count15_tot = 0\n",
    "count15_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count15_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count15_loc += 1\n",
    "  count15_tot += count15_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count23_tot = 0\n",
    "count23_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "     count23_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count23_loc += 1\n",
    "  count23_tot += count23_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count24_tot = 0\n",
    "count24_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count24_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count24_loc += 1\n",
    "  count24_tot += count24_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count25_tot = 0\n",
    "count25_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count25_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count25_loc += 1\n",
    "  count25_tot += count25_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count34_tot = 0\n",
    "count34_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count34_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "      count34_loc += 1\n",
    "  count34_tot += count34_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count35_tot = 0\n",
    "count35_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count35_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "      count35_loc += 1\n",
    "  count35_tot += count35_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 4| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count45_tot = 0\n",
    "count45_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count45_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "      count45_loc += 1\n",
    "  count45_tot += count45_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1')\n",
    "users = train_new_part.userid.unique()\n",
    "count11_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count11_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2')\n",
    "users = train_new_part.userid.unique()\n",
    "count22_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count22_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count33_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count33_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count44_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count44_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count55_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count55_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "rat_dist_matrix[0][0] = count11_tot\n",
    "rat_dist_matrix[0][1] = rat_dist_matrix[1][0]= count12_tot\n",
    "rat_dist_matrix[0][2] = rat_dist_matrix[2][0]= count13_tot\n",
    "rat_dist_matrix[0][3] = rat_dist_matrix[3][0]= count14_tot\n",
    "rat_dist_matrix[0][4] = rat_dist_matrix[4][0]= count15_tot\n",
    "rat_dist_matrix[1][1] = count22_tot\n",
    "rat_dist_matrix[1][2] = rat_dist_matrix[2][1] = count23_tot\n",
    "rat_dist_matrix[1][3] = rat_dist_matrix[3][1] = count24_tot\n",
    "rat_dist_matrix[1][4] = rat_dist_matrix[4][1] = count25_tot\n",
    "rat_dist_matrix[2][2] = count33_tot\n",
    "rat_dist_matrix[2][3] = rat_dist_matrix[3][2] = count34_tot\n",
    "rat_dist_matrix[2][4] = rat_dist_matrix[4][2] = count35_tot\n",
    "rat_dist_matrix[3][3] = count44_tot\n",
    "rat_dist_matrix[3][4] = rat_dist_matrix[4][3] = count45_tot\n",
    "rat_dist_matrix[4][4] = count55_tot       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = np.sum(rat_dist_matrix)\n",
    "rat_dist_matrix /= summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_dist_matrix[0,0] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[1,1] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[2,2] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[3,3] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[4,4] += np.random.uniform(low=0.0, high=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linalg.cholesky(rat_dist_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1542.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0164, Coverage@5 = 0.0949\n",
      "Validation : HR@10 = 0.0554, MRR@10 == 0.0195, Coverage@10 = 0.1337\n",
      "Validation : HR@20 = 0.0880, MRR@20 == 0.0217, Coverage@20 = 0.1796\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1359.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0317, MRR@5 == 0.0188, Coverage@5 = 0.0988\n",
      "Validation : HR@10 = 0.0598, MRR@10 == 0.0226, Coverage@10 = 0.1309\n",
      "Validation : HR@20 = 0.0950, MRR@20 == 0.0250, Coverage@20 = 0.1772\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1444.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0352, MRR@5 == 0.0207, Coverage@5 = 0.0993\n",
      "Validation : HR@10 = 0.0642, MRR@10 == 0.0245, Coverage@10 = 0.1315\n",
      "Validation : HR@20 = 0.1047, MRR@20 == 0.0273, Coverage@20 = 0.1777\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1446.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0334, MRR@5 == 0.0205, Coverage@5 = 0.1007\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0245, Coverage@10 = 0.1304\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0273, Coverage@20 = 0.1769\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1284.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0325, MRR@5 == 0.0203, Coverage@5 = 0.1004\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0244, Coverage@10 = 0.1304\n",
      "Validation : HR@20 = 0.1029, MRR@20 == 0.0272, Coverage@20 = 0.1769\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:55<00:00,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0800 achieved with mlrank=(45, 45, 5)\n",
      "Best MRR=0.0279 achieved with mlrank=(40, 45, 5)\n",
      "COV=0.1560 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1100.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0290, MRR@5 == 0.0126, Coverage@5 = 0.1161\n",
      "Test : HR@10 = 0.0528, MRR@10 == 0.0157, Coverage@10 = 0.1549\n",
      "Test : HR@20 = 0.1038, MRR@20 == 0.0190, Coverage@20 = 0.2077\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ProjectRecSysV3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
