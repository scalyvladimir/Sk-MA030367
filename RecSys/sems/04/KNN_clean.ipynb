{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, diags\n",
    "from scipy.sparse.linalg import norm as spnorm\n",
    "\n",
    "from polara import get_movielens_data\n",
    "from polara.preprocessing.dataframes import leave_one_out, reindex\n",
    "\n",
    "from dataprep import transform_indices\n",
    "from evaluation import topn_recommendations, model_evaluate, downvote_seen_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_movielens_data(include_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_, holdout_ = leave_one_out(data, target='timestamp', sample_top=True, random_state=0)\n",
    "\n",
    "assert holdout_.set_index('userid')['timestamp'].ge(\n",
    "    training_\n",
    "    .groupby('userid')\n",
    "    ['timestamp'].max()\n",
    ").all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, data_index = transform_indices(training_, 'userid', 'movieid')\n",
    "holdout = reindex(holdout_, data_index.values(), filter_invalid=True)\n",
    "holdout = holdout.sort_values('userid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-based KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_uknn_model(config, data, data_description):\n",
    "    # get indices of observed data\n",
    "    user_idx = data[data_description['users']].values\n",
    "    item_idx = data[data_description['items']].values\n",
    "    relscore = data[data_description['feedback']].values\n",
    "    # construct rating matrix\n",
    "    shape = (data_description['n_users'], data_description['n_items'])\n",
    "    user_item_mtx = coo_matrix((relscore, (user_idx, item_idx)), shape=shape)\n",
    "    # compute similarity matrix and normalization coefficients\n",
    "    user_similarity = cosine_similarity(user_item_mtx)\n",
    "    # R = K D A\n",
    "    sim_weights = (\n",
    "        user_similarity\n",
    "        ._with_data(np.abs(user_similarity.data))\n",
    "        .sum(axis=1)\n",
    "        .A.squeeze()\n",
    "    )\n",
    "    normalizer = np.divide(1., sim_weights, where=sim_weights>0)\n",
    "    return user_item_mtx.tocsr(), user_similarity, normalizer\n",
    "\n",
    "def cosine_similarity(matrix):\n",
    "    row_norm = spnorm(matrix, axis=1).squeeze()\n",
    "    inv_norm = np.divide(1., row_norm, where=row_norm>0)\n",
    "    matrix_normed = diags(inv_norm).dot(matrix)\n",
    "    similarity = matrix_normed.dot(matrix_normed.T)\n",
    "    similarity.setdiag(0)\n",
    "    similarity.eliminate_zeros()\n",
    "    return similarity.tocsr()\n",
    "\n",
    "def uknn_model_scoring(params, testset, testset_description):\n",
    "    user_item_mtx, user_similarity, normalizer = params\n",
    "    test_users = testset_description['test_users']\n",
    "    test_similarity = user_similarity[test_users, :].dot(diags(normalizer))\n",
    "    scores = test_similarity.dot(user_item_mtx).A\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    feedback = 'rating',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    "    test_users = holdout[data_index['users'].name].values\n",
    ")\n",
    "data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uknn_params = build_uknn_model({}, training, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uknn_scores = uknn_model_scoring(uknn_params, None, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_data = training.query('userid in @data_description[\"test_users\"]')\n",
    "downvote_seen_items(uknn_scores, seen_data, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uknn_recs = topn_recommendations(uknn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HR={:.3}, MRR={:.3}, COV={:.3}'.format(*model_evaluate(uknn_recs, holdout, data_description)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>\n",
    "\n",
    "- In your opinion, how the evaluation scores will change if we sample holdout items randomly?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-based KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_iknn_model(config, data, data_description):\n",
    "    # get indices of observed data\n",
    "    user_idx = data[data_description['users']].values\n",
    "    item_idx = data[data_description['items']].values\n",
    "    relscore = data[data_description['feedback']].values\n",
    "    # construct rating matrix\n",
    "    shape = (data_description['n_users'], data_description['n_items'])\n",
    "    user_item_mtx = coo_matrix((relscore, (user_idx, item_idx)), shape=shape)\n",
    "    # compute similarity matrix and normalization coefficients\n",
    "    item_similarity = cosine_similarity(user_item_mtx.T)\n",
    "    sim_weights = \n",
    "    normalizer = \n",
    "    return user_item_mtx.tocsr(), item_similarity, normalizer\n",
    "\n",
    "\n",
    "def iknn_model_scoring(params, testset, testset_description):\n",
    "    user_item_mtx, item_similarity, normalizer = params\n",
    "    test_users = testset_description['test_users']\n",
    "    test_similarity = \n",
    "    scores = \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iknn_params = build_iknn_model({}, training, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iknn_scores = iknn_model_scoring(iknn_params, None, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvote_seen_items(iknn_scores, seen_data, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iknn_recs = topn_recommendations(iknn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HR={:.3}, MRR={:.3}, COV={:.3}'.format(*model_evaluate(iknn_recs, holdout, data_description)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "009c838d92940ae6fa3c0eca0f0908a58be7fe030119f0cd30e204cb459dcff7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('rstest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
